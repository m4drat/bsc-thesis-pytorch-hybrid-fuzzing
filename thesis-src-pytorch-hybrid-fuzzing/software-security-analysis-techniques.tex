\section{Software Security Analysis Techniques}

As we have seen in the previous section, software security is a question of paramount importance in the modern world. Due to the increasing complexity of software systems, it is no longer feasible to rely only on manual code reviews and testing to ensure that they are secure. Instead, a variety of automated analysis techniques have been developed to help developers detect and address security vulnerabilities in their software.

The security analysis techniques can be broadly divided into two categories:

\begin{itemize}
	\item Static Analysis
	\item Dynamic Analysis
\end{itemize}

In this section, we will provide an overview of static analysis and then delve into a detailed examination of dynamic analysis techniques.

\subsection{Static Analysis}

A set of techniques known as static analysis involves analyzing the source code of a program without executing it. This approach allows us to detect a wide range of problems in the code, potentially examining all possible execution paths.

Although static analysis tends to be more exhaustive, it suffers a lot from false positives as well as false negatives. Furthermore, static analysis tends to be very slow and resource-intensive, especially for large codebases.

To mitigate these concerns, dynamic analysis is frequently employed in conjunction with static analysis. Although it may not be as comprehensive as static analysis, it allows identifying issues that static analysis may miss.

\subsection{Dynamic Analysis}

Dynamic analysis, also known as fuzzing is one of the most popular techniques for finding bugs and vulnerabilities in software. It involves running a program with various inputs and monitoring its behavior. The goal of fuzzing is to detect error conditions in the program by observing its behavior under different inputs.

Consider example \ref{lst:example1}. This program takes a string as an input and checks if the first four characters are equal to "\textbf{FUZZ}". If they are, the program crashes. Otherwise, it does nothing.

\begin{listing}[htp]
	\centering
	\begin{minipage}{.6\linewidth}
		\begin{minted}[linenos=true, tabsize=4]{c}
void crash(char* buf) {
	if (buf[0] == 'F') {
		if (buf[1] == 'U') {
			if (buf[2] == 'Z') {
				if (buf[3] == 'Z') {
					*(int*)NULL = 0x1337;
				}
			}
		}
	}
}
		\end{minted}
	\end{minipage}
	\caption{Fuzzing example}
	\label{lst:example1}
\end{listing}

The goal of a generic fuzzer would be to automatically find an input that would cause the program to crash.

The simplest way to do so would be to exhaustively test all possible inputs. While this works well in theory and is guaranteed to find the bug, it is not feasible in practice, as the number of possible inputs grows exponentially with the size of the input. For a program that processes a string of 10 characters, where each character can be any of the 127 ASCII characters, the total number of possible inputs is $127^{10} \approx 1.0915 \times 10^{21}$. This number is far too large to be tested in a reasonable amount of time. Instead, a smarter approach is required.

\subsubsection{Fuzzers Overview}

To compensate for the exponential growth of the input space, fuzzers use various techniques to guide the input generation. For example, state-of-the-art, general-purpose fuzzer AFL++ \cite{AFLplusplus-Woot20} uses a technique called \textit{coverage-guided fuzzing} to generate inputs that are more likely to trigger bugs. This technique involves instrumenting the program to collect code coverage information and then using this information to guide the generation of inputs towards unexplored parts of the program.

Another example of input generation techniques used by fuzzers is \textit{grammar-based fuzzing}. This technique involves defining a grammar that describes the structure and syntax of valid inputs for a given program. The fuzzer then generates inputs that conform to this grammar, exploring different paths through the grammar to generate diverse inputs. This technique is used by various fuzzers, including Nautilus \cite{nautilus-grammar-fuzzer}, Superion \cite{superion-grammar-fuzzer}, Gramatron \cite{gramatron-effective-grammar-aware-fuzzing}, and others.

Besides different approaches to input generation, fuzzers are also distinguished by the type of target they are designed to test. For example, Nyx \cite{nyx-hypervisor-fuzzer-usenix21} or kAFL \cite{kafl-usenix17} are fuzzers designed to work on a hypervisor level allowing to fuzz OS kernels, drivers, and other hard-to-test components. On the other hand, AFL++ or LibFuzzer are examples of general-purpose fuzzers.

\subsubsection{Fuzz Testing Algorithm}

While fuzzers might look very different on the surface, they all share the same basic structure and follow a similar algorithm. In the paper \cite{the-art-science-and-engineering-of-fuzzing-a-survey}, the authors present a high-level overview of the fuzzing process.

Omitting some details, the fuzzing process can be summarized as follows:

\begin{enumerate}
	\item Preprocessing - prepare a corpus of inputs, instrument the program to collect coverage information, etc.
	\item Scheduling - select fuzzing strategies, etc.
	\item Input generation - select an input from the corpus, mutate the input, generate new inputs, etc.
	\item Input evaluation - run the program with the input, collect feedback (e.g. coverage information, crashes, etc.)
	\item Continue fuzzing until a stopping condition is met (e.g. a timeout)
\end{enumerate}

To implement the fuzzing process described above, a fuzzing loop can be used as shown in Algorithm \ref{alg:fuzzing-loop}.

\begin{figure}[ht]
	\centering
	\begin{minipage}{.7\linewidth}
		\begin{algorithm}[H]
			\caption{Fuzzing loop}
			\label{alg:fuzzing-loop}
			$queue \gets construct\_queue()$ \\
			\While{should fuzz} {
				$input \gets select\_input(queue)$ \\
				$input \gets mutate(input)$ \\
				$feedback \gets run\_program(input)$ \\
				\If{feedback is crash} {
					$report\_bug(input)$ \\
				}

				\If{feedback is interesting} {
					$queue.push(input)$ \\
				}
			}
		\end{algorithm}
	\end{minipage}
\end{figure}

The algorithm presented in Algorithm \ref{alg:fuzzing-loop} provides a simplified representation of the fuzzing process that allows us to concentrate on specific components of the fuzzer.

The natural modularity of the fuzzing process has proven to be beneficial, as shown by the example of LibAFL \cite{libafl-ccs21}. This fuzzer has taken advantage of this modular design by enabling users to create their custom implementations of individual components, thereby allowing greater flexibility and customization of the fuzzing process to tackle specific challenges or meet particular requirements.

\subsubsection{Individual Fuzzer Components}

To further understand the different techniques used by fuzzers, let's take a look at some papers that focus on individual components of the fuzzing process.

One important component is the mutation engine used to generate new inputs from existing ones. In the paper \cite{redqueen-ndss19}, the authors propose a new mutation strategy called Redqueen, which utilizes feedback from previous executions to build input-to-state correspondence. This allows Redqueen to solve simple comparison-based constraints, such as the one in the Listing \ref{lst:example2}, assuming the input-to-state mapping is one-to-one.

\begin{listing}[htp]
	\centering
	\begin{minipage}{.6\linewidth}
		\begin{minted}[linenos=true, tabsize=4]{c}
if (strcmp(buf, "FuZzing1sC00L") == 0) {
	*(int*)NULL = 0x1337;
}
		\end{minted}
	\end{minipage}
	\caption{Example solvable by Redqueen}
	\label{lst:example2}
\end{listing}

Another important component is the input selection strategy. In the paper \cite{effective-seed-scheduling-for-fuzzing-with-graph-centrality-analysis}, the authors propose a new seed selection strategy called \textit{K-Scheduler}, which uses graph centrality analysis to select seeds that are more likely to increase feature coverage. The authors show that this strategy outperforms other seed selection strategies, such as \textit{Entropic}, or next-best AFL-based seed scheduler \textit{RarePath} by 25.89\% and 4.21\%, respectively.

\subsubsection{Challenges}

In conclusion, fuzzing has become one of the best techniques to find bugs in software. Through extensive research, various techniques have been developed and applied to different components of the fuzzing process, such as mutation engines, input selection strategies, and others. However, there are many challenges that haven't been solved yet. Ranging from the scalability of fuzzing to the quality of the generated inputs, there are many areas that can be improved.

One particularly challenging problem is the generation of inputs that satisfy complex constraints. Even with the most advanced fuzzers, it is still difficult, if not impossible, to generate inputs that satisfy constraints such as the one in Listing \ref{lst:example3}. This happens because the constraints may involve complex arithmetic operations, or other hard-to-resolve dependencies between input values. As a result, traditional fuzzing techniques that rely on random or mutation-based input generation with coverage feedback are not sufficient to solve this problem.

\begin{listing}[htp]
	\centering
	\begin{minipage}{.6\linewidth}
		\begin{minted}[linenos=true, tabsize=4]{c}
void vuln(int key) {
	if (key * 0xa9a57b == 0x1337beef) {
		error();
	}
}
		\end{minted}
	\end{minipage}
	\caption{Example solvable by symbolic execution}
	\label{lst:example3}
\end{listing}

That is where another set of techniques called \textit{Symbolic Interpretation} comes into play.

\subsection{Symbolic Interpretation}

Symbolic interpretation, also known as symbolic execution, aims to solve the problem of generating inputs that satisfy complex constraints, such as the one in Listing \ref{lst:example3}.

Essentially, symbolic execution is a powerful technique that enables us to run a program with symbolic inputs instead of concrete ones. By treating program states as sets of constraints on these inputs, we can systematically explore different paths through the code and generate new test cases that can reveal hidden bugs.

For example, the state of the program in Listing \ref{lst:example3} can be defined by this equation: \mintinline{python}{key * 0xa9a57b = 0x1337beef}. Depending on whether this equation is satisfied or not, we either take the \texttt{true} or the \texttt{false} branch. By solving this equation, we can generate an input that would open up the \texttt{true} branch, and thus trigger the \texttt{error()} function. For this particular example, the input \mintinline{python}{0x1337beef / 0xa9a57b = 0x1d} would satisfy the equation and trigger the error. What is notable, for classical fuzzers, it would require exhaustively testing all possible inputs to find this one, as there is no feedback which would guide the fuzzer towards this input.

Now that we have covered the fundamentals of symbolic execution, let us delve deeper into the various components of the symbolic execution process.

\subsubsection{Symbolic Representation}

Symbolic representation is the initial stage of the symbolic execution process where program variables and inputs are represented as symbolic expressions that can be mathematically evaluated and manipulated.

To effectively build and update a program's symbolic state based on the instruction semantics, it is necessary to symbolically execute machine code instructions while simultaneously updating the symbolic state. A convenient approach is to use a dynamic binary analysis framework, such as Triton \cite{triton-sstic2015}, which provides an API for symbolic execution and allows us to easily build symbolic expressions from machine code instructions.

In the Listing \ref{lst:example4}, we can see an example of how Triton can be used to symbolically execute a program from Listing \ref{lst:example3}, and generate an equation for the conditional jump instruction.

% an input that would trigger the \texttt{error()} function.

\begin{listing}[htp]
	\centering
	\begin{minipage}{.9\linewidth}
		\begin{minted}[linenos=true, tabsize=4, breaklines=true, fontsize=\small]{python}
from triton import *

>>> # Create the Triton context with a defined architecture
>>> ctx = TritonContext(ARCH.X86_64)

>>> # Symbolize data (optional)
>>> ctx.symbolizeRegister(ctx.registers.eax, 'sym_eax')

>>> # Execute instructions
>>> ctx.processing(Instruction(b"\xb9\x7b\xa5\xa9\x00")) # mov ecx, 0xa9a57b
>>> ctx.processing(Instruction(b"\xf7\xe1"))             # mul ecx
>>> ctx.processing(Instruction(b"\x3d\xef\xbe\x37\x13")) # cmp eax, 0x1337beef

>>> # Get the symbolic expression
>>> zf_expr = ctx.getSymbolicRegister(ctx.registers.zf)
>>> print(zf_expr)
(define-fun ref!14 () (_ BitVec 1) (ite (= ref!8 (_ bv0 32)) (_ bv1 1) (_ bv0 1))) ; Zero flag
	\end{minted}
	\end{minipage}
	\caption{Triton API example}
	\label{lst:example4}
\end{listing}

Triton provides a powerful mechanism for interpreting machine code instructions and updating the symbolic state simultaneously. However, it may not be able to handle certain scenarios such as external library calls or complex OS-dependent instructions like \texttt{syscall}. In such cases, it may be necessary to actually run the program and symbolically execute as much as possible, while concretizing the remaining instructions that cannot be symbolically executed.

This approach is commonly used by various symbolic execution engines, such as QSym \cite{qsym-usenix2018} and others. In the case of QSym, the symbolic execution engine simply concretizes the instructions that cannot be symbolically executed, and then continues with the symbolic execution. This approach is called \textit{concolic execution} and is widely used in symbolic execution engines.

% With the power of Triton we have a way to maintain a symbolic state of the program.

\subsubsection{Dynamic Constraints Collection}

A key component of concolic execution is dynamic constraints collection, which is performed using a concrete executor that runs a program with specific inputs and collects constraints on those inputs.

To accomplish this, dynamic binary instrumentation (DBI) frameworks are commonly employed. DBI frameworks allow for program instrumentation and constraint collection on-the-fly, providing a convenient solution to perform dynamic analysis. Popular DBI frameworks, such as Pin \cite{pintool-2005}, DynamoRIO \cite{dynamorio-thesis}, and QEMU \cite{qemu-usenix2005} can be used for this purpose.

Typically, per-instruction callbacks are used in DBI frameworks to collect constraints as the program is executed. When a callback is triggered, the corresponding instruction is examined, and the constraints on the input values are collected. These constraints are then combined to form a path condition that represents all the constraints encountered during execution.

With the constraints collected, we can now solve them and generate new inputs.

\subsubsection{Constraints Solving}

To solve the constraints collected during dynamic analysis, a constraint solver is needed. The solver takes the path condition generated from the collected constraints and generates new input values that satisfy the condition. To solve the constraints, a wide range of SMT solvers can be employed, such as Z3 \cite{z3-smt-solver}, Bitwuzla \cite{bitwuza-smt-comp-2020}, CVC5 \cite{cvc5-smt-solver}, and others.

The efficiency and accuracy of the solver play a crucial role in the performance of concolic execution. In some cases, the solver may not be able to find a solution, or the solution may be too complex and time-consuming to compute. To address these issues, various techniques such as constraint simplification and pruning can be used to simplify the constraints and reduce the solution space.

Once the solver generates new input values, the program can be executed again with the updated inputs, and the process of constraint collection and solving can be repeated. This iterative process continues until all paths have been explored, or until a specific goal, such as reaching a specific code location or triggering a specific vulnerability, is achieved.

To illustrate the process of constraint solving, we can use the example from Listing \ref{lst:example4}. In this example, we symbolically executed the \texttt{mul} instruction and generated a constraint on the \texttt{ZF} flag. We can now solve this constraint using the Triton API, as shown in Listing \ref{lst:example5}. The solution to the constraint is \texttt{sym\_eax = 0x1d}, which is the value that would trigger the \texttt{error()} function.

\begin{listing}[htp]
	\centering
	\begin{minipage}{.7\linewidth}
		\begin{minted}[linenos=true, tabsize=4, breaklines=true, fontsize=\small]{python}
>>> # Solve constraint
>>> ctx.getModel(zf_expr.getAst() == 0x1)
{0: sym_eax:32 = 0x1d}

>>> # 0x1d * 0xa9a57b is indeed equal to 0x1337beef
>>> hex(0x1d * 0xa9a57b)
'0x1337beef'
\end{minted}
	\end{minipage}
	\caption{Triton getModel() API example}
	\label{lst:example5}
\end{listing}

\subsubsection{Benefits}

With the ability to symbolically execute a program and generate new inputs that satisfy a specific condition, a few obvious benefits arise.

First, we can automatically generate inputs that would open up new paths in the program. This allows us to explore different program states and as a result, test different aspects of the program. This is called \textit{path exploration} and is one of the main benefits that symbolic execution provides.

The second benefit is the ability to not only explore different paths, but also to check security invariants. For example, we can check if a specific code location is reachable, or if a specific condition can be satisfied. This is called \textit{security invariant checking} and is another key benefit of symbolic execution. This technique allows us to check if a specific vulnerability can be triggered, for example, if it is possible to generate such an input that would trigger an out-of-bounds access. Consider the example from Listing \ref{lst:example6}.

\begin{listing}[htp]
	\centering
	\begin{minipage}{.4\linewidth}
		\begin{minted}[linenos=true, tabsize=4]{c}
void vuln(uint32_t index) {
	char data[64];
	if (index < 74)
		data[index] = 0x37;
}
		\end{minted}
	\end{minipage}
	\caption{Security invariants checking example}
	\label{lst:example6}
\end{listing}

The bug here is obvious -- the \texttt{data} array is only 64 bytes long, but the condition \texttt{index < 74} checks that the index is less than 74. This means that any index greater than 63 would trigger an out-of-bounds write. With the automatic security invariant checking, we can check if it is possible to generate such an input that would trigger the vulnerability.

One particular example of a tool that implements this technique is Sydr. In the paper \textit{Symbolic Security Predicates: Hunt Program Weaknesses} \cite{sydr-symbolic-security-predicates}, the authors proposed a technique called \textit{symbolic security predicates} that allows for automatic security invariant checking.

\subsubsection{Challenges}

While symbolic execution provides a lot of benefits, it also comes with a handful of challenges.

\newparagraph{Symbolic Memory}

One of the main challenges of symbolic execution is the ability to build a precise symbolic model of the program. While modeling simple program with scalar values is relatively easy, modeling memory with pointer operations introduces a new level of indirection that makes the process much more difficult. Additionally, performance drops significantly due to the substantial increase in formula size and complexity when compared to scalar-only modes.

Another crucial aspect of the challenge is determining approximate or exact boundaries for symbolic memory accesses. In general case, a symbolic memory dereference could access any memory location, which is infeasible to model. Therefore, we must find a way to limit memory access to a specific range. For instance, in the paper \textit{Towards Symbolic Pointers Reasoning in Dynamic Symbolic Execution} \cite{symbolic-pointers-reasoning}, the authors study this problem and explore various techniques to address it. One approach proposed involves the use of heuristics to determine the leftmost boundary by extracting the concrete portion from the abstract syntax tree of the address expression.

\newparagraph{Unsolvable Constraints}

Another challenge arises from the fact that modern SMT solvers are not perfect at solving all SMT problems efficiently. The SMT problem is known to be NP-complete, which means there is no known algorithm that can solve all SMT problems efficiently. As a result, although modern SMT solvers can handle many real-world problems, there are still scenarios where the solver may fail to find a solution or take an excessively long time to do so. This limitation can hamper the performance and effectiveness of the symbolic execution process.

\newparagraph{Incomplete Symbolic Model}

Additional obstacle of symbolic execution is the potential incompleteness of the symbolic model. It may not always be possible or practical to completely model a program symbolically, especially when dealing with interactions with the outside world, such as system calls. This can result in discrepancies between the symbolic program state and the real one, leading to unsolvable constraints that impede the effectiveness of the technique. However, some approaches, such as concolic testing, can help mitigate this challenge by combining symbolic and concrete execution.

\newparagraph{Path Explosion}

Finally, a significant challenge in various types of program analysis, including symbolic execution, fuzzing, and path-sensitive static analysis, is the path explosion problem. This issue arises because the number of control-flow paths in a program increases exponentially with the program's size. As a result, the symbolic execution engine may not be able to explore all the paths within a reasonable timeframe. To overcome this challenge, researchers have proposed various techniques, such as path pruning and constraint prioritization, that aim to reduce the number of explored paths without compromising the completeness of the analysis. However, these techniques have their limitations, and achieving complete path coverage remains a challenging problem in program analysis.

\subsection{Hybrid Fuzzing}

% Symbolic execution is shown to be a powerful technique for program analysis. However, it is not without its limitations. One of the main challenges of symbolic execution is the path explosion problem. As the number of paths in a program increases exponentially with the program's size, the symbolic execution engine may not be able to explore all the paths within a reasonable timeframe. To overcome this challenge, researchers have proposed various techniques, such as path pruning and constraint prioritization, that aim to reduce the number of explored paths without compromising the completeness of the analysis. However, these techniques have their limitations, and achieving complete path coverage remains a challenging problem in program analysis.

One of the first attempts to combine symbolic execution was presented as a \cite{driller-ndss16}

\subsubsection{Examples}

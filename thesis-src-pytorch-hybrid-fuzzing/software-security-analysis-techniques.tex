\section{Software Security Analysis Techniques}

As we have seen in the previous section, software security is a question of paramount importance in the modern world. Due to the increasing complexity of software systems, it is no longer feasible to rely only on manual code reviews and testing to ensure that they are secure. Instead, a variety of automated analysis techniques have been developed to help developers detect and address security vulnerabilities in their software.

The security analysis techniques can be broadly divided into two categories:

\begin{itemize}
	\item Static Analysis
	\item Dynamic Analysis
\end{itemize}

In this section, we will provide an overview of static analysis and then delve into a detailed examination of dynamic analysis techniques.

\subsection{Static Analysis}

A set of techniques known as static analysis involves analyzing the source code of a program without executing it. This approach allows us to detect a wide range of problems in the code, potentially examining all possible execution paths.

Although static analysis tends to be more exhaustive, it suffers a lot from false positives as well as false negatives. Furthermore, static analysis tends to be very slow and resource-intensive, especially for large codebases.

To mitigate these concerns, dynamic analysis is frequently employed in conjunction with static analysis. Although it may not be as comprehensive as static analysis, it allows identifying issues that static analysis may miss.

\subsection{Dynamic Analysis}

Dynamic analysis, also known as fuzzing is one of the most popular techniques for finding bugs and vulnerabilities in software. It involves running a program with various inputs and monitoring its behavior. The goal of fuzzing is to detect error conditions in the program by observing its behavior under different inputs.

Consider example \ref{lst:example1}. This program takes a string as an input and checks if the first four characters are equal to "\textbf{FUZZ}". If they are, the program crashes. Otherwise, it does nothing.

\begin{listing}[htp]
	\centering
	\begin{minipage}{.6\linewidth}
		\begin{minted}[linenos=true, tabsize=4]{c}
void crash(char* buf) {
	if (buf[0] == 'F') {
		if (buf[1] == 'U') {
			if (buf[2] == 'Z') {
				if (buf[3] == 'Z') {
					*(int*)NULL = 0x1337;
				}
			}
		}
	}
}
		\end{minted}
	\end{minipage}
	\caption{Fuzzing example}
	\label{lst:example1}
\end{listing}

The goal of a generic fuzzer would be to automatically find an input that would cause the program to crash.

The simplest way to do so would be to exhaustively test all possible inputs. While this works well in theory and is guaranteed to find the bug, it is not feasible in practice, as the number of possible inputs grows exponentially with the size of the input. For a program that processes a string of 10 characters, where each character can be any of the 127 ASCII characters, the total number of possible inputs is $127^{10} \approx 1.0915 \times 10^{21}$. This number is far too large to be tested in a reasonable amount of time. Instead, a smarter approach is required.

\subsubsection{Fuzzers Overview}

To compensate for the exponential growth of the input space, fuzzers use various techniques to guide the input generation. For example, state-of-the-art, general-purpose fuzzer AFL++ \cite{AFLplusplus-Woot20} uses a technique called \textit{coverage-guided fuzzing} to generate inputs that are more likely to trigger bugs. This technique involves instrumenting the program to collect code coverage information and then using this information to guide the generation of inputs towards unexplored parts of the program.

Another example of input generation techniques used by fuzzers is \textit{grammar-based fuzzing}. This technique involves defining a grammar that describes the structure and syntax of valid inputs for a given program. The fuzzer then generates inputs that conform to this grammar, exploring different paths through the grammar to generate diverse inputs. This technique is used by various fuzzers, including Nautilus \cite{nautilus-grammar-fuzzer}, Superion \cite{superion-grammar-fuzzer}, Gramatron \cite{gramatron-effective-grammar-aware-fuzzing}, and others.

Besides different approaches to input generation, fuzzers are also distinguished by the type of target they are designed to test. For example, Nyx \cite{nyx-hypervisor-fuzzer-usenix21} or kAFL \cite{kafl-usenix17} are fuzzers designed to work on a hypervisor level allowing to fuzz OS kernels, drivers, and other hard-to-test components. On the other hand, AFL++ or LibFuzzer are examples of general-purpose fuzzers.

\subsubsection{Fuzz Testing Algorithm}

While fuzzers might look very different on the surface, they all share the same basic structure and follow a similar algorithm. In the paper \cite{the-art-science-and-engineering-of-fuzzing-a-survey}, the authors present a high-level overview of the fuzzing process.

Omitting some details, the fuzzing process can be summarized as follows:

\begin{enumerate}
	\item Preprocessing - prepare a corpus of inputs, instrument the program to collect coverage information, etc.
	\item Scheduling - select fuzzing strategies, etc.
	\item Input generation - select an input from the corpus, mutate the input, generate new inputs, etc.
	\item Input evaluation - run the program with the input, collect feedback (e.g. coverage information, crashes, etc.)
	\item Continue fuzzing until a stopping condition is met (e.g. a timeout)
\end{enumerate}

To implement the fuzzing process described above, a fuzzing loop can be used as shown in Algorithm \ref{alg:fuzzing-loop}.

\begin{figure}[ht]
	\centering
	\begin{minipage}{.7\linewidth}
		\begin{algorithm}[H]
			\caption{Fuzzing loop}
			\label{alg:fuzzing-loop}
			$queue \gets construct\_queue()$ \\
			\While{should fuzz} {
				$input \gets select\_input(queue)$ \\
				$input \gets mutate(input)$ \\
				$feedback \gets run\_program(input)$ \\
				\If{feedback is crash} {
					$report\_bug(input)$ \\
				}

				\If{feedback is interesting} {
					$queue.push(input)$ \\
				}
			}
		\end{algorithm}
	\end{minipage}
\end{figure}

The algorithm presented in Algorithm \ref{alg:fuzzing-loop} provides a simplified representation of the fuzzing process that allows us to concentrate on specific components of the fuzzer.

The natural modularity of the fuzzing process has proven to be beneficial, as shown by the example of LibAFL \cite{libafl-ccs21}. This fuzzer has taken advantage of this modular design by enabling users to create their custom implementations of individual components, thereby allowing greater flexibility and customization of the fuzzing process to tackle specific challenges or meet particular requirements.

\subsubsection{Individual Fuzzer Components}

To further understand the different techniques used by fuzzers, let's take a look at some papers that focus on individual components of the fuzzing process.

One important component is the mutation engine used to generate new inputs from existing ones. In the paper \cite{redqueen-ndss19}, the authors propose a new mutation strategy called Redqueen, which utilizes feedback from previous executions to build input-to-state correspondence. This allows Redqueen to solve simple comparison-based constraints, such as the one in the Listing \ref{lst:example2}, assuming the input-to-state mapping is one-to-one.

\begin{listing}[htp]
	\centering
	\begin{minipage}{.6\linewidth}
		\begin{minted}[linenos=true, tabsize=4]{c}
if (strcmp(buf, "FuZzing1sC00L") == 0) {
	*(int*)NULL = 0x1337;
}
		\end{minted}
	\end{minipage}
	\caption{Example solvable by Redqueen}
	\label{lst:example2}
\end{listing}

Another important component is the input selection strategy. In the paper \cite{effective-seed-scheduling-for-fuzzing-with-graph-centrality-analysis}, the authors propose a new seed selection strategy called \textit{K-Scheduler}, which uses graph centrality analysis to select seeds that are more likely to increase feature coverage. The authors show that this strategy outperforms other seed selection strategies, such as \textit{Entropic}, or next-best AFL-based seed scheduler \textit{RarePath} by 25.89\% and 4.21\%, respectively.

\subsubsection{Challenges}

In conclusion, fuzzing has become one of the best techniques to find bugs in software. Through extensive research, various techniques have been developed and applied to different components of the fuzzing process, such as mutation engines, input selection strategies, and others. However, there are many challenges that haven't been solved yet. Ranging from the scalability of fuzzing to the quality of the generated inputs, there are many areas that can be improved.

One particularly challenging problem is the generation of inputs that satisfy complex constraints. Even with the most advanced fuzzers, it is still difficult, if not impossible, to generate inputs that satisfy constraints such as the one in Listing \ref{lst:example3}. This happens because the constraints may involve complex arithmetic operations, or other hard-to-resolve dependencies between input values. As a result, traditional fuzzing techniques that rely on random or mutation-based input generation with coverage feedback are not sufficient to solve this problem.

\begin{listing}[htp]
	\centering
	\begin{minipage}{.6\linewidth}
		\begin{minted}[linenos=true, tabsize=4]{c}
void vuln(int key) {
	if (key * 0xa9a57b == 0x1337beef) {
		error();
	}
}
		\end{minted}
	\end{minipage}
	\caption{Example solvable by symbolic execution}
	\label{lst:example3}
\end{listing}

That is where another set of techniques called \textit{Symbolic Interpretation} comes into play.

\subsection{Symbolic Interpretation}

Symbolic interpretation, also known as symbolic execution, aims to solve the problem of generating inputs that satisfy complex constraints, such as the one in Listing \ref{lst:example3}.

Essentially, symbolic execution is a powerful technique that enables us to run a program with symbolic inputs instead of concrete ones. By treating program states as sets of constraints on these inputs, we can systematically explore different paths through the code and generate new test cases that can reveal hidden bugs.

For example, the state of the program in Listing \ref{lst:example3} can be defined by this equation: \mintinline{python}{key * 0xa9a57b = 0x1337beef}. Depending on whether this equation is satisfied or not, we either take the \texttt{true} or the \texttt{false} branch. By solving this equation, we can generate an input that would open up the \texttt{true} branch, and thus trigger the \texttt{error()} function. For this particular example, the input \mintinline{python}{0x1337beef / 0xa9a57b = 0x1d} would satisfy the equation and trigger the error. What is notable, for classical fuzzers, it would require exhaustively testing all possible inputs to find this one, as there is no feedback which would guide the fuzzer towards this input.

Now that we have covered the fundamentals of symbolic execution, let us delve deeper into the various components of the symbolic execution process.

\subsubsection{Symbolic Representation}

Symbolic representation is the initial stage of the symbolic execution process where program variables and inputs are represented as symbolic expressions that can be mathematically evaluated and manipulated.

To effectively build and update a program's symbolic state based on the instruction semantics, it is necessary to symbolically execute machine code instructions while simultaneously updating the symbolic state. A convenient approach is to use a dynamic binary analysis framework, such as Triton \cite{triton-sstic2015}, which provides an API for symbolic execution and allows us to easily build symbolic expressions from machine code instructions.

In the Listing \ref{lst:example4}, we can see an example of how Triton can be used to symbolically execute a program from Listing \ref{lst:example3}, and generate an equation for the conditional jump instruction.

% an input that would trigger the \texttt{error()} function.

\begin{listing}[htp]
	\centering
	\begin{minipage}{.9\linewidth}
		\begin{minted}[linenos=true, tabsize=4, breaklines=true, fontsize=\small]{python}
from triton import *

>>> # Create the Triton context with a defined architecture
>>> ctx = TritonContext(ARCH.X86_64)

>>> # Symbolize data (optional)
>>> ctx.symbolizeRegister(ctx.registers.eax, 'sym_eax')

>>> # Execute instructions
>>> ctx.processing(Instruction(b"\xb9\x7b\xa5\xa9\x00")) # mov ecx, 0xa9a57b
>>> ctx.processing(Instruction(b"\xf7\xe1"))             # mul ecx
>>> ctx.processing(Instruction(b"\x3d\xef\xbe\x37\x13")) # cmp eax, 0x1337beef

>>> # Get the symbolic expression
>>> zf_expr = ctx.getSymbolicRegister(ctx.registers.zf)
>>> print(zf_expr)
(define-fun ref!14 () (_ BitVec 1) (ite (= ref!8 (_ bv0 32)) (_ bv1 1) (_ bv0 1))) ; Zero flag

>>> # Solve constraint
>>> ctx.getModel(zf_expr.getAst() == 0x1)
{0: sym_eax:32 = 0x1d}

>>> # 0x1d * 0xa9a57b is indeed equal to 0x1337beef
>>> hex(0x1d * 0xa9a57b)
'0x1337beef'
	\end{minted}
	\end{minipage}
	\caption{Triton API example}
	\label{lst:example4}
\end{listing}

Triton provides a powerful mechanism for interpreting machine code instructions and updating the symbolic state simultaneously. However, it may not be able to handle certain scenarios such as external library calls or complex OS-dependent instructions like \texttt{syscall}. In such cases, it may be necessary to actually run the program and symbolically execute as much as possible, while concretizing the remaining instructions that cannot be symbolically executed.

This approach is widely used by many symbolic execution engines, such as QSym \cite{qsym-usenix2018} and Sydr.

So, we have a way to maintain symbolic state

\subsubsection{Dynamic Constraints Collection}

% bochs, Frida, QEMU, QBDI, tinyinst

Dynamorio \cite{dynamorio-thesis}, pintool \cite{pintool-2005}, QEMU \cite{qemu-usenix2005}

\subsubsection{Constraints Solving}

Z3 \cite{z3-smt-solver}, CVC5 \cite{cvc5-smt-solver}, Bitwuzla \cite{bitwuza-smt-comp-2020}

\subsubsection{Approaches?}

\begin{itemize}
	\item Concolic execution (Offline) - BAP, Sydr, etc.
	\item Fork-based (Online) - KLEE, S2E, etc.
\end{itemize}

\subsubsection{Challenges}

\begin{itemize}
	\item Infinite execution path
	\item Unsolvable constraints
	\item Symbolic modeling (syscalls, external function calls, etc.)
\end{itemize}

\subsection{Hybrid Fuzzing}

One of the first attempts to combine symbolic execution was presented as a \cite{driller-ndss16}
